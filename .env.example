# Configuration pour l'application PatientOverview

# Provider de modèle IA: 'openai', 'ollama' ou 'mistral'
MODEL_PROVIDER=openai

# Nom du modèle à utiliser
# Pour OpenAI: 'gpt-4o', 'gpt-4-turbo', etc.
# Pour Ollama: 'llama3', 'mistral', etc.
# Pour Mistral: 'mistral-small-latest', 'open-mixtral-8x22b', etc.
MODEL_NAME=gpt-4o

# =============================================================================
# API Keys - Secret Resolution
# =============================================================================
# The application automatically handles secrets in both environments:
#
# LOCAL DEVELOPMENT:
#   - Provide raw API key values directly
#   - Example: OPENAI_API_KEY=sk-proj-xxxxx
#
# PRODUCTION (AWS Lambda):
#   - Environment variables are set to SSM parameter names (start with '/')
#   - Example: OPENAI_API_KEY=/patient-overview/openai-api-key
#   - The secrets_manager.py module automatically detects and retrieves from SSM
#
# No code changes needed - the same codebase works in both environments!
# =============================================================================

# Clé API OpenAI (obligatoire si MODEL_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here

# Clé API Mistral (obligatoire si MODEL_PROVIDER=mistral)
MISTRAL_API_KEY=your_mistral_api_key_here

# URL de base optionnelle (ex: pour Ollama local ou un proxy)
# BASE_URL=http://localhost:11434
